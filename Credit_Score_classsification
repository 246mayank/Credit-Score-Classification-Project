
# Credit Score Classification - Multi-Model Comparison
# Author: [Your Name]
# Description: Classification pipeline with multiple models for credit score prediction using Kaggle data

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, accuracy_score
import xgboost as xgb
import lightgbm as lgb
import warnings
warnings.filterwarnings('ignore')

def load_data(train_path, test_path):
	train = pd.read_csv(train_path)
	test = pd.read_csv(test_path)
	return train, test

def drop_identifiers(df):
	columns_to_drop = ['ID', 'Customer_ID', 'Name', 'SSN']
	return df.drop(columns=[col for col in columns_to_drop if col in df.columns], errors='ignore')

def clean_numerics(df, cols):
	for col in cols:
		if col in df.columns:
			df[col] = pd.to_numeric(df[col], errors='coerce')
	return df

def correct_and_impute(df, impute_cols):
	# Age correction
	if 'Age' in df.columns:
		df.loc[(df['Age'] < 18) | (df['Age'] > 100), 'Age'] = np.nan
	# Impute with median
	imputation_dict = {col: df[col].median() for col in impute_cols if col in df.columns}
	df.fillna(value=imputation_dict, inplace=True)
	return df, imputation_dict

def convert_credit_history_age(df):
	if 'Credit_History_Age' in df.columns:
		df['Credit_History_Age'].fillna('0 Years and 0 Months', inplace=True)
		years = df['Credit_History_Age'].str.extract(r'(\d+)').astype(int)
		months = df['Credit_History_Age'].str.extract(r'(\d+)\s*Months').astype(int)
		df['Credit_History_Age_Months'] = (years * 12) + months
		df.drop(columns=['Credit_History_Age'], inplace=True)
	return df

def handle_type_of_loan(df, vectorizer=None, fit=True):
	if 'Type_of_Loan' not in df.columns:
		return df, vectorizer
	df['Type_of_Loan'].fillna('No_Loan', inplace=True)
	def smart_tokenizer(s):
		s_cleaned = s.replace(', and ', ',')
		tokens = [token.strip() for token in s_cleaned.split(',')]
		return tokens
	if fit:
		vectorizer = CountVectorizer(tokenizer=smart_tokenizer)
		loan_features = vectorizer.fit_transform(df['Type_of_Loan'])
	else:
		loan_features = vectorizer.transform(df['Type_of_Loan'])
	loan_df = pd.DataFrame(loan_features.toarray(), columns=vectorizer.get_feature_names_out())
	loan_df = loan_df.add_prefix('loan_')
	df = df.reset_index(drop=True)
	loan_df = loan_df.reset_index(drop=True)
	df = pd.concat([df, loan_df], axis=1)
	df.drop(columns=['Type_of_Loan'], inplace=True)
	return df, vectorizer

def encode_features(df, target=False):
	if target:
		score_mapping = {'Poor': 0, 'Standard': 1, 'Good': 2}
		df['Credit_Score'] = df['Credit_Score'].map(score_mapping)
	cols_to_one_hot_encode = ['Month', 'Occupation', 'Credit_Mix', 'Payment_of_Min_Amount', 'Payment_Behaviour']
	df = pd.get_dummies(df, columns=[col for col in cols_to_one_hot_encode if col in df.columns], drop_first=True)
	return df

def preprocess(df, impute_cols, vectorizer=None, fit_vectorizer=True, imputation_dict=None):
	df = drop_identifiers(df)
	df = clean_numerics(df, impute_cols)
	if imputation_dict is None:
		df, imputation_dict = correct_and_impute(df, impute_cols)
	else:
		df.fillna(value=imputation_dict, inplace=True)
	df = convert_credit_history_age(df)
	df, vectorizer = handle_type_of_loan(df, vectorizer, fit=fit_vectorizer)
	df = encode_features(df)
	return df, vectorizer, imputation_dict

def train_and_evaluate_models(X_train, X_val, y_train, y_val):
    """
    Train multiple models and return their performance metrics
    """
    results = {}
    
    print("=" * 60)
    print("TRAINING AND EVALUATING MULTIPLE MODELS")
    print("=" * 60)
    
    # 1. Random Forest
    print("\n1. Training Random Forest...")
    rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
    rf_model.fit(X_train, y_train)
    rf_pred = rf_model.predict(X_val)
    rf_accuracy = accuracy_score(y_val, rf_pred)
    
    results['Random Forest'] = {
        'model': rf_model,
        'predictions': rf_pred,
        'accuracy': rf_accuracy,
        'report': classification_report(y_val, rf_pred, target_names=['Poor (0)', 'Standard (1)', 'Good (2)'])
    }
    
    # 2. XGBoost with Grid Search
    print("\n2. Training XGBoost with hyperparameter tuning...")
    
    # Define parameter grid for XGBoost
    param_grid_xgb = {
        'max_depth': [3, 5, 7],
        'n_estimators': [100, 200],
        'learning_rate': [0.1, 0.05]
    }
    
    xgb_base = xgb.XGBClassifier(
        objective='multi:softmax',
        num_class=3,
        random_state=42,
        use_label_encoder=False,
        eval_metric='mlogloss',
        n_jobs=-1
    )
    
    grid_search_xgb = GridSearchCV(
        estimator=xgb_base,
        param_grid=param_grid_xgb,
        cv=3,
        verbose=1,
        n_jobs=-1
    )
    
    grid_search_xgb.fit(X_train, y_train)
    
    # Best XGBoost model
    best_xgb = grid_search_xgb.best_estimator_
    xgb_pred = best_xgb.predict(X_val)
    xgb_accuracy = accuracy_score(y_val, xgb_pred)
    
    results['XGBoost'] = {
        'model': best_xgb,
        'predictions': xgb_pred,
        'accuracy': xgb_accuracy,
        'best_params': grid_search_xgb.best_params_,
        'report': classification_report(y_val, xgb_pred, target_names=['Poor (0)', 'Standard (1)', 'Good (2)'])
    }
    
    # 3. LightGBM with Grid Search
    print("\n3. Training LightGBM with hyperparameter tuning...")
    
    # Define parameter grid for LightGBM
    param_grid_lgb = {
        'n_estimators': [100, 200, 500],
        'learning_rate': [0.1, 0.05],
        'num_leaves': [20, 31, 40],
    }
    
    lgb_base = lgb.LGBMClassifier(
        objective='multiclass',
        num_class=3,
        random_state=42,
        n_jobs=-1,
        verbose=-1
    )
    
    grid_search_lgb = GridSearchCV(
        estimator=lgb_base,
        param_grid=param_grid_lgb,
        cv=3,
        verbose=1,
        n_jobs=-1
    )
    
    grid_search_lgb.fit(X_train, y_train)
    
    # Best LightGBM model
    best_lgb = grid_search_lgb.best_estimator_
    lgb_pred = best_lgb.predict(X_val)
    lgb_accuracy = accuracy_score(y_val, lgb_pred)
    
    results['LightGBM'] = {
        'model': best_lgb,
        'predictions': lgb_pred,
        'accuracy': lgb_accuracy,
        'best_params': grid_search_lgb.best_params_,
        'report': classification_report(y_val, lgb_pred, target_names=['Poor (0)', 'Standard (1)', 'Good (2)'])
    }
    
    return results

def print_model_comparison(results):
    """
    Print comprehensive comparison of all models
    """
    print("\n" + "=" * 80)
    print("MODEL PERFORMANCE COMPARISON")
    print("=" * 80)
    
    # Summary table
    print("\nACCURACY SUMMARY:")
    print("-" * 40)
    for model_name, result in results.items():
        print(f"{model_name:<15}: {result['accuracy']:.4f}")
    
    # Best model
    best_model = max(results.items(), key=lambda x: x[1]['accuracy'])
    print(f"\nBEST MODEL: {best_model[0]} with accuracy: {best_model[1]['accuracy']:.4f}")
    
    # Detailed reports
    print("\n" + "=" * 80)
    print("DETAILED CLASSIFICATION REPORTS")
    print("=" * 80)
    
    for model_name, result in results.items():
        print(f"\n{model_name.upper()} PERFORMANCE:")
        print("-" * 50)
        print(f"Accuracy: {result['accuracy']:.4f}")
        
        if 'best_params' in result:
            print(f"Best Parameters: {result['best_params']}")
        
        print("\nClassification Report:")
        print(result['report'])
        print("-" * 50)
    
    return best_model[0], best_model[1]['model']

def create_submission_with_best_model(best_model, X_test, test_customer_ids, filename='submission_best_model.csv'):
    """
    Create submission file using the best performing model
    """
    print(f"\nCreating submission file using the best model...")
    test_predictions = best_model.predict(X_test)
    
    # Map back to text labels
    reverse_score_mapping = {0: 'Poor', 1: 'Standard', 2: 'Good'}
    mapped_predictions = pd.Series(test_predictions).map(reverse_score_mapping)
    
    # Create submission DataFrame
    submission_df = pd.DataFrame({
        'Customer_ID': test_customer_ids,
        'Credit_Score': mapped_predictions
    })
    
    submission_df.to_csv(filename, index=False)
    print(f"Submission file saved as '{filename}'")
    print("Preview of submission:")
    print(submission_df.head())
    
    return submission_df

def main():
    # File paths
    train_path = 'train.csv'
    test_path = 'test.csv'
    
    # Columns to clean/impute
    impute_cols = [
        'Age', 'Annual_Income', 'Monthly_Inhand_Salary', 'Num_of_Loan',
        'Num_of_Delayed_Payment', 'Changed_Credit_Limit', 'Num_Credit_Inquiries',
        'Outstanding_Debt', 'Amount_invested_monthly', 'Monthly_Balance'
    ]

    print("Loading and preprocessing data...")
    # Load data
    train, test = load_data(train_path, test_path)

    # Preprocess train data
    train, vectorizer, imputation_dict = preprocess(train, impute_cols, fit_vectorizer=True)
    train = encode_features(train, target=True)
    X_train_full = train.drop(columns=['Credit_Score'])
    y_train_full = train['Credit_Score']

    # Preprocess test data
    test_customer_ids = test['Customer_ID'] if 'Customer_ID' in test.columns else None
    test, _, _ = preprocess(test, impute_cols, vectorizer=vectorizer, fit_vectorizer=False, imputation_dict=imputation_dict)
    # Align columns
    X_test_final, X_train_full = test.align(X_train_full, join='right', axis=1, fill_value=0)

    print("\nCreating validation split for self-evaluation...")
    # Create validation split for self-evaluation
    X_train_split, X_val, y_train_split, y_val = train_test_split(
        X_train_full, y_train_full, test_size=0.2, random_state=42, stratify=y_train_full
    )
    
    print(f"Training set shape: {X_train_split.shape}")
    print(f"Validation set shape: {X_val.shape}")

    # Feature scaling
    print("\nApplying feature scaling...")
    scaler = StandardScaler()
    X_train_split_scaled = scaler.fit_transform(X_train_split)
    X_val_scaled = scaler.transform(X_val)
    X_test_scaled = scaler.transform(X_test_final)

    # Train and evaluate multiple models
    results = train_and_evaluate_models(X_train_split_scaled, X_val_scaled, y_train_split, y_val)
    
    # Print comparison
    best_model_name, best_model = print_model_comparison(results)
    
    # Create submission with best model
    create_submission_with_best_model(best_model, X_test_scaled, test_customer_ids)
    
    print(f"\n{best_model_name} was selected as the best model for final predictions!")

if __name__ == "__main__":
    main()
